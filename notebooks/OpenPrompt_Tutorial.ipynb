{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb4479b-0a72-4d1d-bae1-fafbe2ceea71",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tanikina/low-resource-nlp-lab/blob/main/notebooks/OpenPrompt_Tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff7d6a9-0f61-4656-8954-794265bdfd8c",
   "metadata": {},
   "source": [
    "<img src=\"images/open-prompt.png\" alt=\"OpenPrompt\" width=\"200\"/>\n",
    "\n",
    "**Documentation:** [https://thunlp.github.io/OpenPrompt/](https://thunlp.github.io/OpenPrompt/)\n",
    "\n",
    "**Examples & Tutorials:** [https://github.com/thunlp/OpenPrompt/tree/main/tutorial](https://github.com/thunlp/OpenPrompt/tree/main/tutorial)\n",
    "\n",
    "**Paper:** [OpenPrompt: An Open-source Framework for Prompt-learning (Ding et al., 2022)](https://aclanthology.org/2022.acl-demo.10.pdf)\n",
    "\n",
    "### OpenPrompt Workflow\n",
    "<img src=\"images/open-prompt-workflow.png\" alt=\"OpenPrompt Workflow\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2097b4-38a3-4c46-bb66-a39c58207bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openprompt\n",
    "! pip install datasets\n",
    "! pip install transformers [torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a7fa5aa-4f85-4d0e-87a3-e4365eeb65a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from openprompt import PromptForClassification\n",
    "from openprompt.plms import load_plm\n",
    "\n",
    "from openprompt.prompts import ManualTemplate, ManualVerbalizer, SoftTemplate\n",
    "from openprompt import PromptDataLoader\n",
    "\n",
    "from openprompt.data_utils.utils import InputExample\n",
    "from openprompt.data_utils.data_processor import DataProcessor\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from typing import List, Dict\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65336a8e-1f93-4cf1-a32f-8409bbfde5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ceee9d-356b-4236-9e46-c1a2b93dad74",
   "metadata": {},
   "source": [
    "### üóÉÔ∏è Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d990254-a0a2-448f-8876-0b6f65616b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPromptProcessor(DataProcessor):\n",
    "\n",
    "    def __init__(self, label_word2idx: Dict[int, str]):\n",
    "        super().__init__()\n",
    "        self.label_word2idx = label_word2idx\n",
    "        self.idx2label_word = {v: k for k, v in self.label_word2idx.items()}\n",
    "\n",
    "    def get_examples(self, dataset: Dataset) -> List[InputExample]:        \n",
    "        examples = []\n",
    "        full_src_lst = []\n",
    "        full_tgt_lst = []\n",
    "        for i in range(len(dataset)):\n",
    "            full_src_lst.append(dataset[\"speaker\"][i] + \" - \" + dataset[\"text\"][i])\n",
    "            label_idx = dataset[\"label\"][i]\n",
    "            full_tgt_lst.append(self.idx2label_word[label_idx])\n",
    "        for i, (src, tgt, tag) in enumerate(zip(full_src_lst, full_tgt_lst, dataset[\"label\"])):\n",
    "            example = InputExample(guid=str(i), text_a=src, tgt_text=tgt, label=tag)\n",
    "            examples.append(example)\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "510b39fe-08ce-4f58-81e7-d9331d06fa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"guid\": \"24\",\n",
      "  \"label\": 3,\n",
      "  \"meta\": {},\n",
      "  \"text_a\": \"UGV 1 - Frage: der Einsatzbefehl gilt auch f\\u00fcr UGV 1?\",\n",
      "  \"text_b\": \"\",\n",
      "  \"tgt_text\": \"Nachfragen\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preparing the data\n",
    "orig_data = load_dataset(\"DFKI/radr_intents\")\n",
    "train_task_dataset = orig_data[\"train\"] # train_task_dataset = Dataset.from_csv(\"radr_intents/train.csv\")\n",
    "dev_task_dataset = orig_data[\"validation\"] \n",
    "test_task_dataset = orig_data[\"test\"] \n",
    "\n",
    "# Mapping between the labels and their \"verbalization\" (e.g., for label 1 \"Einsatzbefehl\" means \"order\")\n",
    "label_word2idx = {\"Absage\":0, \"Einsatzbefehl\":1, \"Informieren\":2, \"Nachfragen\":3, \"Anruf\":4, \"Antwort\":5, \"Sonstiges\":6, \"Zusage\":7}\n",
    "dp = CustomPromptProcessor(label_word2idx)\n",
    "\n",
    "dataset = dict()\n",
    "dataset[\"train\"] = dp.get_examples(train_task_dataset)\n",
    "dataset[\"validation\"] = dp.get_examples(dev_task_dataset)\n",
    "dataset[\"test\"] = dp.get_examples(test_task_dataset)\n",
    "print(dataset[\"train\"][24])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8928429-51e9-4362-a3b8-979b60d3e036",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e021672-344e-4617-af0d-10c0ab1a547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MT5ForConditionalGeneration, MT5Tokenizer, MT5Config\n",
    "from openprompt import plms\n",
    "from openprompt.plms import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67fce546-8eae-4752-a227-bcef8204d295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:240: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "tokenizing: 2610it [00:00, 2730.14it/s]\n",
      "tokenizing: 310it [00:00, 2843.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# Setting up the hyperparameters\n",
    "num_epochs = 5\n",
    "pmodel_name = \"tradrz-\"+str(num_epochs)+\"-epochs\"\n",
    "template_filename = \"tradrz_soft_template_simple.txt\"\n",
    "init_from_vocab = True\n",
    "num_soft_tokens = 10\n",
    "batch_size = 8\n",
    "model = \"t5\" # \"mt5\" or \"t5\"\n",
    "model_name_or_path = \"t5-base\" # \"google/mt5-base\" or \"t5-base\"\n",
    "max_seq_len = 32\n",
    "\n",
    "if model == \"mt5\":\n",
    "    plms._MODEL_CLASSES[\"mt5\"]= ModelClass(**{\"config\": MT5Config, \"tokenizer\": MT5Tokenizer, \\\n",
    "                                              \"model\": MT5ForConditionalGeneration, \"wrapper\": T5TokenizerWrapper})\n",
    "\n",
    "store_dir = \"saved_models_openprompt/\"\n",
    "if not os.path.exists(store_dir):\n",
    "    os.makedirs(store_dir)\n",
    "\n",
    "plm, tokenizer, model_config, WrapperClass = load_plm(model, model_name_or_path)\n",
    "\n",
    "# We need to add special tokens for mT5 since it does not have them by default\n",
    "if model == \"mt5\":\n",
    "    tokenizer.add_tokens([\"<extra_id_0>\"])\n",
    "    plm.resize_token_embeddings(len(tokenizer))\n",
    "    tokenizer.additional_special_tokens = [\"<extra_id_0>\"]\n",
    "    tokenizer.additional_special_token_ids = [len(tokenizer)]\n",
    "  \n",
    "# Preparing the template and the verbalizer\n",
    "# mytemplate = SoftTemplate(model=plm, tokenizer=tokenizer, num_tokens=num_soft_tokens, \\\n",
    "#                          initialize_from_vocab=init_from_vocab).from_file(template_filename, choice=0)\n",
    "mytemplate = SoftTemplate(model=plm, tokenizer=tokenizer, num_tokens=num_soft_tokens, \\\n",
    "                          initialize_from_vocab=init_from_vocab, text=\"{'placeholder':'text_a'} {'mask'}\")\n",
    "myverbalizer = ManualVerbalizer(tokenizer, num_classes=8, \\\n",
    "                                label_words=[[\"Absage\"], [\"Einsatzbefehl\"], [\"Informieren\"], [\"Nachfragen\"], \\\n",
    "                                             [\"Anruf\"], [\"Antwort\"], [\"Sonstiges\"], [\"Zusage\"]])\n",
    "# Preparing the training data\n",
    "train_dataloader = PromptDataLoader(dataset=dataset[\"train\"], template=mytemplate, tokenizer=tokenizer, \\\n",
    "                                    tokenizer_wrapper_class=WrapperClass, max_seq_length=max_seq_len, \\\n",
    "                                    decoder_max_length=5, batch_size=batch_size, shuffle=True, \\\n",
    "                                    teacher_forcing=False, predict_eos_token=False, truncate_method=\"head\")\n",
    "\n",
    "# Initializing the prompt model\n",
    "prompt_model = PromptForClassification(plm=plm, template=mytemplate, verbalizer=myverbalizer, freeze_plm=False)\n",
    "prompt_model = prompt_model.to(device)\n",
    "\n",
    "# Setting up the loss function and the optimizer\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in prompt_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in prompt_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=5e-5)\n",
    "\n",
    "# Preparing the vaildation data\n",
    "validation_dataloader = PromptDataLoader(dataset=dataset[\"validation\"], template=mytemplate, tokenizer=tokenizer, \\\n",
    "                                         tokenizer_wrapper_class=WrapperClass, max_seq_length=max_seq_len, decoder_max_length=5, \\\n",
    "                                         batch_size=batch_size,shuffle=False, teacher_forcing=False, predict_eos_token=False, \\\n",
    "                                         truncate_method=\"head\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e176f0c-64d2-4dbb-9712-88462993494e",
   "metadata": {},
   "source": [
    "### üöÄ Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adba1b4f-e95f-41ff-8d9e-c9096a118641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, average training loss: 0.8241562300592388\n",
      "Epoch 0, average validation loss: 6.9102330058813095\n",
      "Epoch 1, average training loss: 0.353786771567339\n",
      "Epoch 1, average validation loss: 2.9663660077569194\n",
      "Epoch 2, average training loss: 0.19130322488810902\n",
      "Epoch 2, average validation loss: 1.6040039625233755\n",
      "Epoch 3, average training loss: 0.1229876136365959\n",
      "Epoch 3, average validation loss: 1.031203837414535\n",
      "Epoch 4, average training loss: 0.09304335780957264\n",
      "Epoch 4, average validation loss: 0.7801327693264167\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "dev_loss_min = None\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for step, inputs in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        logits = prompt_model(inputs)\n",
    "        labels = inputs['label']\n",
    "        loss = loss_func(logits, labels)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(\"Epoch {}, average training loss: {}\".format(epoch, total_loss/(step+1)), flush=True)\n",
    "    \n",
    "    # Evaluation on the validation set\n",
    "    with torch.no_grad():\n",
    "        cur_loss = 0\n",
    "        for step, inputs in enumerate(validation_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            logits = prompt_model(inputs)\n",
    "            labels = inputs['label']\n",
    "            loss = loss_func(logits, labels)\n",
    "            cur_loss += loss.item()\n",
    "        cur_loss = cur_loss/(step+1)\n",
    "        if dev_loss_min is None or cur_loss<dev_loss_min:\n",
    "            dev_loss_min = cur_loss\n",
    "            torch.save(prompt_model.state_dict(), store_dir+pmodel_name+\".pt\")\n",
    "    print(\"Epoch {}, average validation loss: {}\".format(epoch, total_loss/(step+1)), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d92c5e-6407-4fd0-b9a4-e7de703ddfcd",
   "metadata": {},
   "source": [
    "### ‚úÖ Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aae99a4-df66-4e94-a06d-b50a0d631f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 605it [00:00, 2536.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: tradrz-5-epochs\n",
      "Accuracy: 0.715702479338843\n",
      "Predicted: Information_geben\n",
      "Gold: Absage\n",
      "Text: UGV 1 - Keine Thermik. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: UAV - Markus f√ºr Dirk. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: TL - Dirk, kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: TL - Das ist gut. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: UAV - Markus f√ºr Dirk. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: TL - Dirk, kommen. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: UGV 1 - Ja, verstanden, zwei bis drei Vermisste. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Absage\n",
      "Text: UGV 1 - Nein. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: TL - Ja. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: UGV 1 - Das ist richtig, ich habe eine Person gefunden. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: TL - Das ist verstanden. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: UAV - Markus f√ºr Dirk. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: TL - Dirk, kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: UAV - Ja zumindest in der N√§he davon direkt neben dem Hochofen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: UGV 1 - Ja, Andreas mitgeh√∂rt, zwei Personen in der N√§he des Hochofens. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: UAV - Markus f√ºr Dirk. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: TL - Dirk, kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: UGV 1 - Ja, Andreas mitgeh√∂rt, drei gehf√§hige Personen. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: UGV 1 - Ja, verstanden. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: UAV - Markus f√ºr Dirk. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: TL - Dirk, kommen. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: UGV 1 - Ja, verstanden. \n",
      "\n",
      "Predicted: Kontakt_Bestaetigung\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: TL - Hier Markus an alle Operator. \n",
      "\n",
      "Predicted: Einsatzbefehl\n",
      "Gold: Information_geben\n",
      "Text: TL - Zwei Minuten Funkstille zwecks √úbergabe. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: UGV 1 - Andreas verstanden. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: UGV 2 - Daniel verstanden. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: UAV - Hier ist Dirk. \n",
      "\n",
      "Predicted: Kontakt_Bestaetigung\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: TL - Hier Markus an alle Operator. \n",
      "\n",
      "Predicted: Sonstiges\n",
      "Gold: Information_geben\n",
      "Text: TL - Wechsel des Leaders. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: UGV 2 - Daniel hat verstanden. \n",
      "\n",
      "Predicted: Einsatzbefehl\n",
      "Gold: Information_geben\n",
      "Text: TL - Also, ich wiederhole: wir haben vier Personen, die sind gehf√§hig und eine weitere Person mit Warnweste auch gehf√§hig. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: TL - Thorsten h√∂rt Andreas kommt. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Information_nachfragen\n",
      "Text: TL - Ich hoffe, ihr habt auch eine Landmarke gesetzt. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: UGV 1 - Ja, verstanden. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: UAV - Thorsten f√ºr Dirk. \n",
      "\n",
      "Predicted: Einsatzbefehl\n",
      "Gold: Information_geben\n",
      "Text: TL - Ja, such mal noch weiter. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: UAV - Thorsten f√ºr Dirk. \n",
      "\n",
      "Predicted: Kontakt_Bestaetigung\n",
      "Gold: Information_geben\n",
      "Text: UGV 1 - Das war Roboter 1. \n",
      "\n",
      "Predicted: Information_nachfragen\n",
      "Gold: Einsatzbefehl\n",
      "Text: TL - Roboter 1, k√∂nnen Sie den Standort nochmal anfahren? \n",
      "\n",
      "Predicted: Information_nachfragen\n",
      "Gold: Einsatzbefehl\n",
      "Text: TL - Und von dort geradeaus weiter auf die Person zufahren? \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: UGV 1 - Ja, ich kann den Standort direkt nochmal anfahren. \n",
      "\n",
      "Predicted: Einsatzbefehl\n",
      "Gold: Information_geben\n",
      "Text: TL - Gehe davon aus, das ist trotzdem die liegende Person ist, die wir suchen und finden sollten. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: TL - Ja, korrekt, da stehen bleiben. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: UGV 1 - Ja ich fahre den Rettungskr√§ften √ºber meinen Angriffsweg entgegen und versuche sie zu lotsen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Absage\n",
      "Text: UGV 2 - Aber teilweise unf√§hig das umzusetzen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Einsatzbefehl\n",
      "Text: TL - Ben√∂tige Luftbild mit m√∂glichst der leblosen Person, die auf dem W√§rmescan den ich hier habe zu sehen ist. \n",
      "\n",
      "Predicted: Einsatzbefehl\n",
      "Gold: Absage\n",
      "Text: TL - Nein, das ist ein Foto von dem Roboter 1. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: UGV 1 - Ja, richtig. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: UAV - Ja, die ist immer noch in der Luft. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Absage\n",
      "Text: UAV - Drohne landet wegen leerem Akku. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: UAV - Thorsten f√ºr Dirk. \n",
      "\n",
      "Predicted: Einsatzbefehl\n",
      "Gold: Information_geben\n",
      "Text: TL - Ich m√∂chte Infrarot-Bilder haben mit dem Ziel Leckagen festzustellen beziehungsweise W√§rmestrahlung. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: UAV - Ja, verstanden. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: UAV - Das ist korrekt. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: UGV 2 - Roboter 2 hat verstanden. \n",
      "\n",
      "Predicted: Einsatzbefehl\n",
      "Gold: Information_geben\n",
      "Text: TL - Wiederhole: am Treppenausgang blauer Kanister. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: UGV 1 - Ja, richtig. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Einsatzbefehl\n",
      "Text: TL - Ben√∂tige Foto. \n",
      "\n",
      "Predicted: Einsatzbefehl\n",
      "Gold: Information_geben\n",
      "Text: TL - Ich werte das Bild aus. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: UGV 1 - Ja, von dem Fass. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: TL - Thorsten h√∂rt kommen. \n",
      "\n",
      "Predicted: Einsatzbefehl\n",
      "Gold: Zusage\n",
      "Text: TL - Ja, w√ºrde ich mich dar√ºber freuen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Einsatzbefehl\n",
      "Text: TL - Br√§uchte nur noch ein klareres Foto von der Person. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: UAV - Gut. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: UGV 1 - Roboter 1 hat verstanden. √úbungsende. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: UGV 2 - Roboter 2 hat verstanden. √úbungsende. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: UAV - Drohne hat verstanden. √úbungsende. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Einsatzbefehl\n",
      "Text: GF 1 - Alpha ist f√ºr Sie zur Unterst√ºtzung angefordert. Kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: Alpha - Ja, ist verstanden. Ende. \n",
      "\n",
      "Predicted: Information_nachfragen\n",
      "Gold: Information_geben\n",
      "Text: RobLW - √Ñh, wo sind die? Wir haben Bilder von Bodenrobotern. Kommen. \n",
      "\n",
      "Predicted: Einsatzbefehl\n",
      "Gold: Information_nachfragen\n",
      "Text: Gamma - Ja, Frage: Gibt es von dem Trupp Epsilon die 360-Grad-Bilder? Kommen. \n",
      "\n",
      "Predicted: Kontakt_Bestaetigung\n",
      "Gold: Information_geben\n",
      "Text: GF 1 - Ich komme wieder. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: Gamma - Das ist verstanden. Ende. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: GF 1 - Ja, ist verstanden. Ich komme wieder. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: RobLW - RobLW an Zugf√ºhrer, Panoramabilder sind jetzt verf√ºgbar. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Einsatzbefehl\n",
      "Text: ZF - Ja, das ist soweit verstanden. Ende. Nein, kein Ende, mit, √§h, dem Telemasten die Position an der T√ºr durchf√ºhren und dann nach Personen in der Wohnung gucken. Kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: Gamma - Gamma hat verstanden. Kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: GF 1 - Delta bricht ab. Stattdessen ein Trupp im √∂st- im westlichen Bereich des Erdgeschosses. Verstanden. Ende. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Einsatzbefehl\n",
      "Text: GF 1 - Sie k√∂nnen wieder zum RobLW verlegen. Kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: Alpha - Alpha hat verstanden. Ende. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: Gamma - Gruppenf√ºhrer eins von Gamma, hat verstanden, Ende. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: ELW 2 - Andr√© f√ºr ELW zwo. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: Einsatzleiter - √Ñh, der ELW zwo vom Einsatzleiter. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: ELW 2 - Hier ist der ELW zwo. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: ELW 2 - Ja, verstanden. \n",
      "\n",
      "Predicted: Einsatzbefehl\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Zu √úberfliegen der Einsatzstelle f√ºr die Aufstellung der Fahrzeuge inklusiv des, √§h, Lagebildes. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: Einsatzleiter - Ja, das ist so korrekt.  \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: Florian-GW-DUK 1 - Hier der Florian Dortmund null GW-DUK eins, kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Einsatzbefehl\n",
      "Text: ELW 2 - Wir haben einen Einsatzauftrag f√ºr Sie von der Einsatzleitung. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Einsatzbefehl\n",
      "Text: ELW 2 - Einmal den √úberflug √ºber die Fahrzeugaufstellung - und einmal den √úberflug √ºber das Schadens- das Schadensbild. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Ja, ist richtig verstanden. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Sonstiges\n",
      "Text: ELW 2 - Eins zwo. \n",
      "\n",
      "Predicted: Kontakt_Bestaetigung\n",
      "Gold: Information_nachfragen\n",
      "Text: ELW 2 - Andr√©, kannst du mich h√∂ren? \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: Andr√© - Ja,  \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Sonstiges\n",
      "Text: Andr√© - Nochmal, warte. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Sonstiges\n",
      "Text: ELW 2 - Eins zwo eins zwo. \n",
      "\n",
      "Predicted: Einsatzbefehl\n",
      "Gold: Sonstiges\n",
      "Text: Andr√© - Z√§hl‚Äô mal langsam bis zehn. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Sonstiges\n",
      "Text: ELW 2 - Eins, zwo, drei, vier, f√ºnf, sechs, sieben, acht, neun, zehn. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Sonstiges\n",
      "Text: ELW 2 - Siehste, Andr√©, mit mir will auch keiner sprechen.  \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: Florian-GW-DUK 1 - Florian Kreis Viersen - \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: ELW 2 - Der ELW zwo h√∂rt, kommen. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: Florian-GW-DUK 1 - Viersen, zehn, E, L, W, zwo, eins von Florian Dortmund null, G, W, D, U, K, eins, kommen. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Ja, okay,  \n",
      "\n",
      "Predicted: Kontakt_Bestaetigung\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Der ELW zwo h√∂rt. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Das ist korrekt. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Ja, das ist richtig verstanden. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: Florian-GW-DUK 1 - Florian Dortmund null eins von Florian Dortmund null - G, W, D, U, K, eins, kommen. Florian Kreis Viersen - Zehn, E, L, W, zwo, eins von Florian, G, W, D, U, K, eins, kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: ELW 2 - Der ELW zwo eins h√∂rt. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: DUK 1 - DUK eins f√ºr den ELW zwo, kommen. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Das ist verstanden. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: DUK 1 - Das ist verstanden. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: Florian-GW-DUK 1 - Florian Kreis Viersen, zehn, E, L, W, zwo, eins, von Florian Dortmund null, G, W, D, U, K, eins, kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: ELW 2 - Der Viersen zehn ELW zwo eins h√∂rt. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: Florian-GW-DUK 1 - Florian Kreis Viersen - zehn, E, L, W, zwo, eins von Florian Dortmund null, GW-DUK - zehn, kommen. \n",
      "\n",
      "Predicted: Information_nachfragen\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Ich frage nach. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Information_nachfragen\n",
      "Text: Einsatzleiter - √Ñh, komm‚Äô nochmal wieder, \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Ja, das ist auch verstanden. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: ELW 2 - Der DUK ELW von ELW zwo, kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: Florian-GW-DUK 1 - Florian Kreis Viersen, zehn, ELW zwo - eins, von Florian Dortmund null, GW-DUK eins, kommen. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Ja, das ist verstanden.  \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: Florian-GW-DUK 1 - Florian Kreis Viersen, zehn, ELW zwo, eins, von Florian Dortmund null, GW-DUK zehn, kommen. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: Einsatzleiter - Ja, so korrekt. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Einsatzbefehl\n",
      "Text: ELW 2 - Ja, Einsatzauftrag vom Einsatzleiter - einmal einen √úberflug √ºber die Einsatzstelle mit Infrarot, kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: Florian-GW-DUK 1 - Verstanden. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: Florian-GW-DUK 1 - Florian Kreis Viersen, ELW zwo, eins, von Florian Dortmund null, G, W, D, U, K, eins. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Das‚Äô verstanden. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Ja, verstanden, 47 Meter, Korridor zwei. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Information_nachfragen\n",
      "Text: Einsatzleiter - Ja, Frage: Habt ihr ‚Äônen aktuellen √úberblick dadr√ºber, wie viele Drohnen wir hier vor Ort haben? \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Einsatzbefehl\n",
      "Text: ELW 2 - Haben Sie die M√∂glichkeit, zu eruieren, wie viel‚Äô Drohnen hier an der Einsatzstelle sind, beziehungsweise welche F√§higkeiten die besitzen? \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: Florian-GW-DUK 1 - Das wird erkundet. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Einsatzbefehl\n",
      "Text: ELW 2 - Wenn m√∂glich, an den ELW zwo per Mail. \n",
      "\n",
      "Predicted: Einsatzbefehl\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: Einsatzleiter - ELW zwo von, √§h, Einsatzleiter. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Einsatzbefehl\n",
      "Text: Einsatzleiter - √Ñh, ja, k√∂nntet ihr noch ‚Äône Info an die Leitstelle geben, dass wir hier Feuer machen? \n",
      "\n",
      "Predicted: Einsatzbefehl\n",
      "Gold: Zusage\n",
      "Text: Florian-GW-DUK 1 - K√∂nnen wir machen. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Sieben Drohnen Feuerwehr Kreis Viersen vor Ort, ja. \n",
      "\n",
      "Predicted: Sonstiges\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: ELW 2 - Andr√©. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Information_nachfragen\n",
      "Text: ELW 2 - Ja, aber kurze Frage eben vorab: Entf√§llt der Arbeitsauftrag f√ºr die, √§h, den GW-DUK? \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Zw√∂lf Drohnen von der Hochschule Gelsenkirchen. Verstanden. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: ELW 2 - ELW DUK von dem ELW Kreis Viersen, kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: Florian-GW-DUK 1 - Florian Dortmund null EW-DUK, √§h, GW-DUK eins h√∂rt. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Sonstiges\n",
      "Text: ELW 2 - Trotzdem danke f√ºr die Vorleistung.  \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Sonstiges\n",
      "Text: ELW 2 - So kenn‚Äô wir uns. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: Einsatzleiter - Ja, das‚Äô verstanden. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: Florian-GW-DUK 1 - Florian Kreis Viersen, zehn E, L, W, zwo, eins von Florian Dortmund null GW-DUK zehn, kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: ELW 2 - Der ELW zwo h√∂rt, kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Information_nachfragen\n",
      "Text: ELW 2 - Kommen Sie nochmal. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Der Funk is‚Äô besetzt, ja. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: Einsatzleiter - ELW zwo f√ºr den Einsatzleiter. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Einsatzbefehl\n",
      "Text: Einsatzleiter - Ja, Pause befohlen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: ELW 2 - Pause befohlen. Verstanden. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: Florian-GW-DUK 1 - Florian Dortmund null GW-DUK eins. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Einsatzbefehl\n",
      "Text: ELW 2 - √Ñh, es ist eine Pause, an alle, die die- √§h, den ELW zwo h√∂ren k√∂nnen, eine Pause. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: Florian-GW-DUK 1 - Das‚Äô verstanden. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: Einsatzleiter - Ja, das ist verstanden. \n",
      "\n",
      "Predicted: Einsatzbefehl\n",
      "Gold: Information_geben\n",
      "Text: Einsatzleiter - Ja, √§h, kannst du mir jetzt gleich geben. F√ºr dich als R√ºckmeldung: Der GW-DUK hat jetzt den Folgeeinsatz in Dortmund, die packen jetzt zusammen, und, √§h, fahren dann dahin. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Ja, verstanden. GW-DUK ist zu einem, √§h, Einsatz - √§h, ist aus der √úbung ausgetreten, und, √§h, wir werden mit den Drohnen jetzt direkt Kontakt aufnehmen. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: Einsatzleiter - Ja, das ist so korrekt. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Ja, das‚Äô auch so verstanden. Eine Drohne √ºberfliegt grade die Einsatzstelle. \n",
      "\n",
      "Predicted: Kontakt_Anfrage\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: Einsatzleiter - ELW von Einsatzleiter. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Einsatzbefehl\n",
      "Text: Einsatzleiter - Dann bitte eine Anforderung f√ºr den Abschnittsleiter Drohne: Nochmal einen √úberflug √ºber das Einsatzgebiet mit Infrarotkamera. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Zusage\n",
      "Text: ELW 2 - Ein, √§h, Arbeitsauftrag an den Abschnitt Drohne: Ein √úberflug √ºber das Schadensobjekt mit Infrarot. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: Einsatzleiter - Ja, so korrekt. \n",
      "\n",
      "Predicted: Einsatzbefehl\n",
      "Gold: Zusage\n",
      "Text: Drohne - √úberflug des Schadensgebiets mit starker - starker Verrauchung mit Infrarot, verstanden. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: ELW 2 - Ja, des ist korrekt. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Sonstiges\n",
      "Text: ELW 2 - Warten Sie. \n",
      "\n",
      "Predicted: Kontakt_Anfrage\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: Einsatzleiter - Einsatzleiter f√ºr den ELW zwo, kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Bestaetigung\n",
      "Text: ELW 2 - Hier ist der ELW zwo, kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Kontakt_Anfrage\n",
      "Text: ELW 2 - Abschnitt zwei Drohne f√ºr den ELW zwo, kommen. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Information_nachfragen\n",
      "Text: ELW 2 - Sie hatten gerufen.  \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: Drohne - Das ist richtig. \n",
      "\n",
      "Predicted: Zusage\n",
      "Gold: Information_geben\n",
      "Text: Drohne - An der Ausfahrt zwo null f√ºnf. \n",
      "\n",
      "Predicted: Information_geben\n",
      "Gold: Information_nachfragen\n",
      "Text: Drohne - Ja, ich bin aus null eins null zum Erkundeeinsatz Br√ºggen, habt ihr da irgendwas N√§heres? \n",
      "\n",
      "Accuracy: 0.716 matched: 433 total: 605\n",
      "F1 scores:\n",
      "Absage F1: 0.545\n",
      "Einsatzbefehl F1: 0.612\n",
      "Information_geben F1: 0.721\n",
      "Information_nachfragen F1: 0.901\n",
      "Kontakt_Anfrage F1: 0.824\n",
      "Kontakt_Bestaetigung F1: 0.827\n",
      "Sonstiges F1: 0.267\n",
      "Zusage F1: 0.319\n",
      "Macro F1: 0.627\n",
      "Micro F1: 0.716\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the test set\n",
    "test_dataloader = PromptDataLoader(dataset=dataset[\"test\"], template=mytemplate, tokenizer=tokenizer, \\\n",
    "                                   tokenizer_wrapper_class=WrapperClass, max_seq_length=max_seq_len, \\\n",
    "                                   decoder_max_length=3, batch_size=batch_size,shuffle=False, \\\n",
    "                                   teacher_forcing=False, predict_eos_token=False, truncate_method=\"head\")\n",
    "\n",
    "prompt_model.load_state_dict(torch.load(store_dir+pmodel_name+\".pt\"))\n",
    "torch.save(prompt_model.template.soft_embeds.data, 'soft_tensors.pt')\n",
    "\n",
    "print(\"Evaluating model:\", pmodel_name)\n",
    "\n",
    "alltexts = []\n",
    "alltexts = [instance.text_a for instance in dataset[\"test\"]]\n",
    "allpreds = []\n",
    "alllabels = []\n",
    "for step, inputs in enumerate(test_dataloader):\n",
    "    inputs = inputs.to(device)\n",
    "    logits = prompt_model(inputs)\n",
    "    labels = inputs['label']\n",
    "    alllabels.extend(labels.cpu().tolist())\n",
    "    allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "all_labels = [\"Absage\", \"Einsatzbefehl\", \"Information_geben\", \"Information_nachfragen\", \"Kontakt_Anfrage\", \"Kontakt_Bestaetigung\", \"Sonstiges\", \"Zusage\"]\n",
    "id2label = dict()\n",
    "for i, label in enumerate(all_labels):\n",
    "    id2label[i] = label\n",
    "\n",
    "scores = dict()\n",
    "for label in all_labels:\n",
    "    scores[label] = {\"tp\":0, \"fp\":0, \"fn\":0}\n",
    "\n",
    "match = 0\n",
    "for i in range(len(allpreds)):\n",
    "    predicted_label = id2label[allpreds[i]]\n",
    "    gold_label = id2label[alllabels[i]]\n",
    "    if predicted_label==gold_label:\n",
    "        match+=1\n",
    "        scores[predicted_label][\"tp\"]+=1\n",
    "    else:\n",
    "        print(\"Predicted:\", predicted_label)\n",
    "        print(\"Gold:\", gold_label)\n",
    "        print(\"Text:\", alltexts[i], \"\\n\")\n",
    "        scores[predicted_label][\"fp\"]+=1\n",
    "        scores[gold_label][\"fn\"]+=1\n",
    "\n",
    "print(\"Accuracy:\", round(match/len(allpreds),3), \"matched:\", match, \"total:\", len(allpreds))\n",
    "print(\"F1 scores:\")\n",
    "\n",
    "micro_prec = 0\n",
    "micro_rec = 0\n",
    "micro_f1 = 0\n",
    "\n",
    "f1scores = 0\n",
    "all_tp = 0\n",
    "all_fp = 0\n",
    "all_fn = 0\n",
    "\n",
    "# Computing F1 scores (per label)\n",
    "for label in all_labels:\n",
    "    tp = scores[label][\"tp\"]\n",
    "    fp = scores[label][\"fp\"]\n",
    "    fn = scores[label][\"fn\"]\n",
    "    all_tp+=tp\n",
    "    all_fp+=fp\n",
    "    all_fn+=fn\n",
    "    if (tp+fp)>0:\n",
    "        prec = tp/(tp+fp)\n",
    "    else:\n",
    "        prec = 0\n",
    "    if (tp+fn)>0:\n",
    "        rec = tp/(tp+fn)\n",
    "    else:\n",
    "        rec = 0\n",
    "    if (prec+rec)>0:\n",
    "        f1score = 2*prec*rec/(prec+rec)\n",
    "    else:\n",
    "        f1score = 0\n",
    "    f1scores+=f1score\n",
    "    print(label, \"F1:\", round(f1score,3))\n",
    "if (all_tp+all_fp)>0:\n",
    "    micro_prec = all_tp/(all_tp+all_fp)\n",
    "if (all_tp+all_fn)>0:\n",
    "    micro_rec = all_tp/(all_tp+all_fn)\n",
    "if (micro_prec+micro_rec)>0:\n",
    "    micro_f1 = 2*micro_prec*micro_rec/(micro_prec+micro_rec)\n",
    "\n",
    "# Computing macro F1 scores\n",
    "print(\"Macro F1:\", round(f1scores/len(all_labels),3))\n",
    "print(\"Micro F1:\", round(micro_f1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c627f504-8320-4ff2-a1ff-396ab76707cf",
   "metadata": {},
   "source": [
    "T5 Results:\n",
    "```\n",
    "Accuracy: 0.716 matched: 433 total: 605\n",
    "F1 scores:\n",
    "Absage F1: 0.545\n",
    "Einsatzbefehl F1: 0.612\n",
    "Information_geben F1: 0.721\n",
    "Information_nachfragen F1: 0.901\n",
    "Kontakt_Anfrage F1: 0.824\n",
    "Kontakt_Bestaetigung F1: 0.827\n",
    "Sonstiges F1: 0.267\n",
    "Zusage F1: 0.319\n",
    "Macro F1: 0.627\n",
    "Micro F1: 0.716\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a5dc90-2e7d-4d5b-8ffb-80bb721529fc",
   "metadata": {},
   "source": [
    "mT5 Results:\n",
    "```\n",
    "Accuracy: 0.615 matched: 372 total: 605\n",
    "F1 scores:\n",
    "Absage F1: 0.4\n",
    "Einsatzbefehl F1: 0.296\n",
    "Information_geben F1: 0.705\n",
    "Information_nachfragen F1: 0.633\n",
    "Kontakt_Anfrage F1: 0.717\n",
    "Kontakt_Bestaetigung F1: 0.805\n",
    "Sonstiges F1: 0.174\n",
    "Zusage F1: 0.188\n",
    "Macro F1: 0.49\n",
    "Micro F1: 0.615\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
